{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "iMvsi1ae0m9D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7abb7546-5c6a-491e-a0a4-7e3e1f21e1f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.27.4-py3-none-any.whl (70 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiohttp\n",
            "  Downloading aiohttp-3.8.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from openai) (4.65.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.9/dist-packages (from openai) (2.27.1)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Collecting yarl<2.0,>=1.0\n",
            "  Downloading yarl-1.8.2-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.9/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Collecting aiosignal>=1.1.2\n",
            "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
            "Collecting async-timeout<5.0,>=4.0.0a3\n",
            "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
            "Collecting frozenlist>=1.1.1\n",
            "  Downloading frozenlist-1.3.3-cp39-cp39-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (158 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting multidict<7.0,>=4.5\n",
            "  Downloading multidict-6.0.4-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
            "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.4 yarl-1.8.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8-O-RF0FzAxf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "import pandas as pd\n",
        "\n",
        "openai.api_key = \"api-key\" ##your api code"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import Data"
      ],
      "metadata": {
        "id": "ih8qMl-ZpeZA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zXKOluJBAywX",
        "outputId": "67b14f5e-1fab-43d6-d870-10a37bc682c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('directory file', sheet_name='Sheet1') ## your file\n",
        "print(df.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcOuPTL2zCJc",
        "outputId": "b25b0292-2a3e-43db-aea1-3902104c9178"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(6, 8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "id": "NKQoIEH50fj8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Starts processing"
      ],
      "metadata": {
        "id": "zV35n5LaEqUV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_sentiment_with_gpt3(text):\n",
        "    prompt = f\"Analyze the following restaurant review and extract each aspect (food, service, price, ambience, place), sentiment (positive, negative, or null), and opinions. If the review contains no facets, the corresponding cell is filled with \\\"null\\\". result format, aspect;sentiment;opinion\\n{text}\"\n",
        "\n",
        "    response = openai.Completion.create(\n",
        "        model=\"text-davinci-003\",\n",
        "        prompt=prompt,\n",
        "        temperature=0,\n",
        "        max_tokens=256,\n",
        "        top_p=1,\n",
        "        frequency_penalty=0,\n",
        "        presence_penalty=0,\n",
        "    )\n",
        "\n",
        "    result_text = response.choices[0].text.strip()\n",
        "    \n",
        "    result_dict = {\"aspect\": [], \"sentiment\": [], \"opinion\": []}\n",
        "    for line in result_text.strip().split('\\n'):\n",
        "        line_parts = line.split(';')\n",
        "        if len(line_parts) == 3:\n",
        "            aspect, sentiment, opinion = line_parts\n",
        "            result_dict[\"aspect\"].append(aspect)\n",
        "            result_dict[\"sentiment\"].append(sentiment)\n",
        "            result_dict[\"opinion\"].append(opinion)\n",
        "\n",
        "    return result_dict"
      ],
      "metadata": {
        "id": "s0Sw3njHjFLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the analyze_sentiment_with_gpt3 function to the 'review' column and expand the result into new columns\n",
        "result_columns = df['review_en'].apply(analyze_sentiment_with_gpt3).apply(pd.Series)\n",
        "\n",
        "# Rename the columns in the result_columns DataFrame\n",
        "result_columns.columns = ['aspect', 'sentiment', 'opinion']\n",
        "\n",
        "# Concatenate the result_columns DataFrame with the original subset_df DataFrame\n",
        "new_df = pd.concat([df, result_columns], axis=1)"
      ],
      "metadata": {
        "id": "ksTfuVb4j2hL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df"
      ],
      "metadata": {
        "id": "b724PEKzkAmt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#save in your google drive\n",
        "new_df.to_excel('filename.xlsx')\n",
        "!cp filename.xlsx \"drive/My Drive/Data scraping/Sundanese Results\""
      ],
      "metadata": {
        "id": "cGYp8M8ASWP2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}